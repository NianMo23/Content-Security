# å†…å®¹å®‰å…¨å®¡æ ¸æ¨¡å‹ä¼˜åŒ–é¡¹ç›®

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä¸“æ³¨äºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å†…å®¹å®‰å…¨å®¡æ ¸ç³»ç»Ÿçš„æŒç»­ä¼˜åŒ–ä¸æ”¹è¿›ã€‚ä»æœ€åˆçš„åŸºç¡€å¾®è°ƒåˆ°æœ€æ–°çš„è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ï¼Œç»å†äº†å®Œæ•´çš„æŠ€æœ¯æ¼”è¿›è·¯çº¿ï¼Œè‡´åŠ›äºè§£å†³å†…å®¹å®¡æ ¸åœºæ™¯ä¸­çš„å…³é”®ä¸šåŠ¡é—®é¢˜ï¼š**é™ä½è¯¯æŠ¥ç‡å’Œæ¼æŠ¥ç‡**ã€‚

### ğŸ¯ æ ¸å¿ƒç›®æ ‡

- **é™ä½æ­£å¸¸å†…å®¹è¯¯æŠ¥ç‡**ï¼šä» 7.41% â†’ < 4%
- **é™ä½è¿è§„å†…å®¹æ¼æŠ¥ç‡**ï¼šä» 6.07% â†’ < 6%  
- **æå‡æ•´ä½“å‡†ç¡®ç‡**ï¼šä» 92% â†’ â‰¥ 96%
- **å¢å¼ºæ¨¡å‹ç½®ä¿¡åº¦**ï¼šé«˜ç½®ä¿¡åº¦é¢„æµ‹æ¯”ä¾‹ > 85%

## ğŸ›£ï¸ æŠ€æœ¯æ¼”è¿›è·¯çº¿

### Phase 1.0ï¼šåŸºç¡€æ¨¡å‹å¾®è°ƒé˜¶æ®µ (æ— ä¿®æ”¹è®­ç»ƒå¾®è°ƒ)

#### ğŸ“… æ—¶é—´çº¿ï¼šé¡¹ç›®åˆæœŸ
#### ğŸ¯ ç›®æ ‡ï¼šå»ºç«‹åŸºç¡€çš„å†…å®¹åˆ†ç±»èƒ½åŠ›

**æŠ€æœ¯ç‰¹ç‚¹ï¼š**
- åŸºäº Qwen3-1.7B é¢„è®­ç»ƒæ¨¡å‹çš„ç›´æ¥å¾®è°ƒ
- æ ‡å‡†çš„åºåˆ—åˆ†ç±»ä»»åŠ¡è®¾è®¡
- ä½¿ç”¨ä¼ ç»Ÿçš„äº¤å‰ç†µæŸå¤±å‡½æ•°
- åŸºç¡€çš„ LoRA (Low-Rank Adaptation) å‚æ•°é«˜æ•ˆå¾®è°ƒ

**æ ¸å¿ƒå®ç°ï¼š**
```python
# åŸºç¡€åˆ†ç±»æ¨¡å‹
class Qwen3ForSequenceClassification:
    def forward(self, input_ids, attention_mask, labels=None):
        outputs = self.base_model(input_ids, attention_mask)
        logits = self.classifier(outputs.last_hidden_state[:, 0])
        loss = F.cross_entropy(logits, labels)
        return loss, logits
```

**ä¸»è¦æ–‡ä»¶ï¼š**
- `qwen3_classification_direct.py` - åŸºç¡€åˆ†ç±»æ¨¡å‹å®ç°
- `train_lora_multi_gpu.py` - å¤šGPUè®­ç»ƒè„šæœ¬
- `test_saved_lora_multi_gpu.py` - æ¨¡å‹æµ‹è¯•è„šæœ¬

**æˆæœä¸å±€é™ï¼š**
- âœ… å»ºç«‹äº†å®Œæ•´çš„è®­ç»ƒå’Œæµ‹è¯•æµç¨‹
- âœ… å®ç°äº†åŸºç¡€çš„å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
- âŒ æ¨¡å‹æ€§èƒ½æœ‰é™ï¼Œå­˜åœ¨æ˜æ˜¾çš„è¯¯æŠ¥å’Œæ¼æŠ¥é—®é¢˜
- âŒ ç¼ºä¹é’ˆå¯¹ä¸šåŠ¡åœºæ™¯çš„ç‰¹æ®Šä¼˜åŒ–

---

### Phase 2.0ï¼šå…­åˆ†ç±»Focal Lossä¼˜åŒ–é˜¶æ®µ

#### ğŸ“… æ—¶é—´çº¿ï¼šä¸­æœŸä¼˜åŒ–
#### ğŸ¯ ç›®æ ‡ï¼šè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡ç»†ç²’åº¦åˆ†ç±»èƒ½åŠ›

**æŠ€æœ¯åˆ›æ–°ï¼š**
- å¼•å…¥ **Focal Loss** è§£å†³æ ·æœ¬ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
- å…­åˆ†ç±»ç²¾ç»†åŒ–ï¼š`æ­£å¸¸`ã€`æ­§è§†`ã€`è¿æ³•è¿è§„`ã€`æ”¿æ²»å®‰å…¨`ã€`æš´æ`ã€`è‰²æƒ…ä½ä¿—`
- åŠ¨æ€æƒé‡è°ƒæ•´å’Œç±»åˆ«å¹³è¡¡ä¼˜åŒ–
- å¢å¼ºçš„è®­ç»ƒç­–ç•¥å’Œæ—©åœæœºåˆ¶

**æ ¸å¿ƒç®—æ³•ï¼š**
```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
```

**æŠ€æœ¯äº®ç‚¹ï¼š**
- **ç±»åˆ«æƒé‡è‡ªé€‚åº”**ï¼šæ ¹æ®æ ·æœ¬åˆ†å¸ƒåŠ¨æ€è°ƒæ•´lossæƒé‡
- **å›°éš¾æ ·æœ¬æŒ–æ˜**ï¼šFocal Lossé‡ç‚¹å…³æ³¨éš¾åˆ†ç±»æ ·æœ¬
- **å¤šç»´åº¦è¯„ä¼°**ï¼šæ¼æŠ¥ç‡ã€è¯¯æŠ¥ç‡ã€F1åˆ†æ•°ç­‰ç»¼åˆæŒ‡æ ‡

**ä¸»è¦æ–‡ä»¶ï¼š**
- `train_lora_multi_gpu.py` - é›†æˆFocal Lossçš„è®­ç»ƒè„šæœ¬
- `test_lora_multi_gpu.py` - å…­åˆ†ç±»æµ‹è¯•å’Œåˆ†æè„šæœ¬
- `analyze_results.py` - è¯¦ç»†çš„ç»“æœåˆ†æå·¥å…·

**æˆæœä¸æŒ‘æˆ˜ï¼š**
- âœ… æ˜¾è‘—æ”¹å–„äº†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
- âœ… æå‡äº†æ•´ä½“åˆ†ç±»ç²¾åº¦
- âœ… å»ºç«‹äº†å®Œå–„çš„è¯„ä¼°ä½“ç³»
- âš ï¸ å…­åˆ†ç±»ä»»åŠ¡å¤æ‚åº¦é«˜ï¼Œéƒ¨åˆ†è¾¹ç•Œæ¡ˆä¾‹éš¾ä»¥åŒºåˆ†
- âš ï¸ ä¾ç„¶å­˜åœ¨ä¸šåŠ¡å…³é”®æŒ‡æ ‡ï¼ˆè¯¯æŠ¥ç‡/æ¼æŠ¥ç‡ï¼‰ä¸å¤Ÿç†æƒ³çš„é—®é¢˜

---

### Phase 3.0ï¼šäºŒåˆ†ç±»ä¼˜åŒ–æ¢ç´¢é˜¶æ®µ (å½“å‰)

#### ğŸ“… æ—¶é—´çº¿ï¼šæœ€æ–°é˜¶æ®µ
#### ğŸ¯ ç›®æ ‡ï¼šèšç„¦æ ¸å¿ƒä¸šåŠ¡éœ€æ±‚ï¼Œæè‡´ä¼˜åŒ–ç²¾åº¦

**æˆ˜ç•¥è½¬å˜ï¼š**
ä»å¤æ‚çš„å…­åˆ†ç±»ç®€åŒ–ä¸ºæ ¸å¿ƒçš„äºŒåˆ†ç±»ä»»åŠ¡ï¼š
- **æ­£å¸¸ç±» (0)**: æ‰€æœ‰ç¬¦åˆè§„èŒƒçš„å†…å®¹
- **è¿è§„ç±» (1)**: æ‰€æœ‰ä¸ç¬¦åˆè§„èŒƒçš„å†…å®¹ï¼ˆåŒ…å«åŸæœ‰çš„5ä¸ªè¿è§„ç±»åˆ«ï¼‰

#### 3.1 åŸºç¡€äºŒåˆ†ç±»ä¼˜åŒ–

**æŠ€æœ¯æ”¹è¿›ï¼š**
```python
class BinaryQwen3ForSequenceClassification:
    def __init__(self, model_path, num_labels=2):
        # ç®€åŒ–çš„äºŒåˆ†ç±»æ¶æ„
        self.classifier = nn.Linear(hidden_size, 2)
        
    def forward(self, input_ids, attention_mask, labels=None):
        # ä¸“é—¨é’ˆå¯¹äºŒåˆ†ç±»ä¼˜åŒ–çš„å‰å‘ä¼ æ’­
        loss = F.cross_entropy(logits, labels)
        return loss, logits
```

**ä¸»è¦æ–‡ä»¶ï¼š**
- `train_binary_lora_multi_gpu.py` - äºŒåˆ†ç±»è®­ç»ƒè„šæœ¬
- `test_binary_lora_multi_gpu.py` - äºŒåˆ†ç±»æµ‹è¯•è„šæœ¬

#### 3.2 è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”å­¦ä¹  (BACL) - ğŸ”¥ æœ€æ–°çªç ´

**æ ¸å¿ƒåˆ›æ–°ç†å¿µï¼š**
é’ˆå¯¹"ç²¾åº¦ä¸é«˜"çš„é—®é¢˜ï¼Œå¼•å…¥é©å‘½æ€§çš„ **è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”æŸå¤± (Boundary-Aware Contrastive Loss)** æ¶æ„ã€‚

**æŠ€æœ¯æ¶æ„ï¼š**

1. **è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”æŸå¤± (BACL)**
```python
class BoundaryAwareContrastiveLoss(nn.Module):
    def forward(self, features, logits, labels):
        # 1. å¯¹æ¯”å­¦ä¹ ï¼šå¢å¼ºç±»é—´è¾¹ç•Œ
        contrastive_loss = self.compute_contrastive_loss(features, labels)
        
        # 2. è¾¹ç•Œæ„ŸçŸ¥ï¼šä½ç½®ä¿¡åº¦æ ·æœ¬è¿œç¦»å†³ç­–è¾¹ç•Œ
        boundary_loss = self.compute_boundary_loss(logits)
        
        # 3. ç±»åˆ«åˆ†ç¦»ï¼šå¢å¼ºç‰¹å¾åˆ†ç¦»åº¦
        separation_loss = self.compute_separation_loss(features, labels)
        
        return self.alpha * contrastive_loss + self.beta * boundary_loss + 0.3 * separation_loss
```

2. **åŒé€šé“ç‰¹å¾æå–å™¨**
```python
class DualChannelFeatureExtractor(nn.Module):
    def forward(self, hidden_states, attention_mask):
        # å…¨å±€è¯­ä¹‰é€šé“
        global_features = self.global_channel(global_repr)
        
        # å±€éƒ¨å…³é”®ç‰¹å¾é€šé“ (æ³¨æ„åŠ›æœºåˆ¶)
        local_features = self.local_channel(local_repr)
        
        # æ™ºèƒ½ç‰¹å¾èåˆ
        fused_features = self.fusion([global_features, local_features])
        return fused_features
```

3. **å¯¹æŠ—æ€§ç‰¹å¾è§£è€¦å™¨**
```python
class AdversarialFeatureDecoupler(nn.Module):
    def forward(self, features):
        # ä»»åŠ¡ç›¸å…³ç‰¹å¾ (ç”¨äºåˆ†ç±»)
        task_relevant = self.task_relevant_encoder(features)
        
        # ä»»åŠ¡æ— å…³ç‰¹å¾ (é¢†åŸŸå…±äº«)
        task_irrelevant = self.task_irrelevant_encoder(features)
        
        # æ¢¯åº¦åè½¬å¯¹æŠ—è®­ç»ƒ
        domain_logits = self.domain_discriminator(
            GradientReversalFunction.apply(task_irrelevant)
        )
        return task_relevant, domain_logits
```

**æ™ºèƒ½æŸå¤±å‡½æ•°ç»„åˆï¼š**
```python
total_loss = (0.3 * ce_loss +           # åŸºç¡€åˆ†ç±»æŸå¤±
             0.7 * bacl_loss +          # BACLæŸå¤± (æ ¸å¿ƒ)
             0.1 * adversarial_loss)    # å¯¹æŠ—æŸå¤±
```

**ä¸»è¦æ–‡ä»¶ï¼š**
- `train_binary_bacl_multi_gpu.py` - BACLè®­ç»ƒè„šæœ¬
- `test_binary_bacl_multi_gpu.py` - BACLæµ‹è¯•åˆ†æè„šæœ¬
- `run_bacl_training.py` - ä¾¿æ·è®­ç»ƒå¯åŠ¨å™¨
- `run_bacl_testing.py` - æ™ºèƒ½æµ‹è¯•å¯åŠ¨å™¨
- `README_BACL.md` - BACLæŠ€æœ¯è¯¦ç»†æ–‡æ¡£

## ğŸ“Š æŠ€æœ¯æ¼”è¿›å¯¹æ¯”

| é˜¶æ®µ | æ¨¡å‹æ¶æ„ | æŸå¤±å‡½æ•° | åˆ†ç±»ä»»åŠ¡ | æ ¸å¿ƒåˆ›æ–° | ä¸šåŠ¡æŒ‡æ ‡ |
|-----|---------|---------|---------|---------|---------|
| **1.0 åŸºç¡€å¾®è°ƒ** | æ ‡å‡†Transformer | äº¤å‰ç†µ | 6åˆ†ç±» | LoRAå¾®è°ƒ | åŸºç¡€æ°´å¹³ |
| **2.0 Focalä¼˜åŒ–** | å¢å¼ºåˆ†ç±»å™¨ | Focal Loss | 6åˆ†ç±» | ç±»åˆ«å¹³è¡¡ | æ˜¾è‘—æå‡ |
| **3.0 äºŒåˆ†ç±»+BACL** | åŒé€šé“+å¯¹æŠ—è§£è€¦ | BACLç»„åˆæŸå¤± | 2åˆ†ç±» | è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”å­¦ä¹  | **ç›®æ ‡ï¼š96%+** |

## ğŸš€ æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿

### 1.0 â†’ 2.0 çš„å…³é”®çªç ´
- **é—®é¢˜è¯†åˆ«**ï¼šç±»åˆ«ä¸å¹³è¡¡å¯¼è‡´æ€§èƒ½ç“¶é¢ˆ
- **è§£å†³æ–¹æ¡ˆ**ï¼šFocal Loss + åŠ¨æ€æƒé‡
- **æ•ˆæœ**ï¼šæ•´ä½“å‡†ç¡®ç‡æå‡ï¼Œå›°éš¾æ ·æœ¬è¯†åˆ«èƒ½åŠ›å¢å¼º

### 2.0 â†’ 3.0 çš„é©å‘½æ€§åˆ›æ–°
- **æˆ˜ç•¥é‡æ„**ï¼šå¤æ‚å¤šåˆ†ç±» â†’ æ ¸å¿ƒäºŒåˆ†ç±»
- **æŠ€æœ¯çªç ´**ï¼šè¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”å­¦ä¹  (BACL)
- **æ¶æ„å‡çº§**ï¼šåŒé€šé“ç‰¹å¾æå– + å¯¹æŠ—æ€§è§£è€¦
- **ç›®æ ‡å¯¼å‘**ï¼šç›´å‡»ä¸šåŠ¡ç—›ç‚¹ï¼Œæè‡´ä¼˜åŒ–ç²¾åº¦

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

```
zzz/
â”œâ”€â”€ ğŸ“ Phase 1.0 - åŸºç¡€å¾®è°ƒ
â”‚   â”œâ”€â”€ qwen3_classification_direct.py      # åŸºç¡€åˆ†ç±»æ¨¡å‹
â”‚   â”œâ”€â”€ train_lora_multi_gpu.py            # åŸºç¡€è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ test_saved_lora_multi_gpu.py       # åŸºç¡€æµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ ğŸ“ Phase 2.0 - Focal Lossä¼˜åŒ–  
â”‚   â”œâ”€â”€ train_lora_multi_gpu.py            # Focal Lossè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ test_lora_multi_gpu.py             # å…­åˆ†ç±»æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ analyze_results.py                 # ç»“æœåˆ†æå·¥å…·
â”‚
â”œâ”€â”€ ğŸ“ Phase 3.0 - äºŒåˆ†ç±»+BACLä¼˜åŒ–
â”‚   â”œâ”€â”€ train_binary_lora_multi_gpu.py     # åŸºç¡€äºŒåˆ†ç±»è®­ç»ƒ
â”‚   â”œâ”€â”€ test_binary_lora_multi_gpu.py      # åŸºç¡€äºŒåˆ†ç±»æµ‹è¯•
â”‚   â”œâ”€â”€ train_binary_bacl_multi_gpu.py     # ğŸ”¥ BACLè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ test_binary_bacl_multi_gpu.py      # ğŸ”¥ BACLæµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ run_bacl_training.py               # ğŸ”¥ BACLè®­ç»ƒå¯åŠ¨å™¨
â”‚   â”œâ”€â”€ run_bacl_testing.py                # ğŸ”¥ BACLæµ‹è¯•å¯åŠ¨å™¨
â”‚   â””â”€â”€ README_BACL.md                     # BACLæŠ€æœ¯æ–‡æ¡£
â”‚
â”œâ”€â”€ ğŸ“ æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ r789-b-50000_train.xlsx           # è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ r789-b-50000_val.xlsx             # éªŒè¯æ•°æ®
â”‚   â””â”€â”€ r789-b-50000_test.xlsx            # æµ‹è¯•æ•°æ®
â”‚
â””â”€â”€ README.md                              # ğŸ“– é¡¹ç›®æ€»è§ˆ (æœ¬æ–‡ä»¶)
```

## ğŸ¯ æ€§èƒ½ç›®æ ‡ä¸é¢„æœŸ

### å½“å‰æŒ‘æˆ˜
- æ­£å¸¸å†…å®¹è¯¯æŠ¥ç‡ï¼š7.41%
- è¿è§„å†…å®¹æ¼æŠ¥ç‡ï¼š6.07%
- æ•´ä½“å‡†ç¡®ç‡ï¼š~92%

### BACLç›®æ ‡ (Phase 3.0)
- **æ­£å¸¸è¯¯æŠ¥ç‡**: < 3% 
- **è¿è§„æ¼æŠ¥ç‡**: < 1% 
- **æ•´ä½“å‡†ç¡®ç‡**: â‰¥ 96% 
- **é«˜ç½®ä¿¡åº¦é¢„æµ‹**: > 85% 

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
```bash
# Python ç¯å¢ƒ
python >= 3.8

# æ ¸å¿ƒä¾èµ–
pip install torch transformers peft pandas numpy scikit-learn tqdm
```

### ğŸ”¥ BACLè®­ç»ƒ (æ¨è)

#### 1. æ ‡å‡†é…ç½®
```bash
python run_bacl_training.py \
  --train_data "./data/r789-b-50000_train.xlsx" \
  --val_data "./data/r789-b-50000_val.xlsx" \
  --output_dir "./lora-bacl-standard" \
  --config_type "standard" \
  --gpu_ids "0,1,2,3,4,5"
```

#### 2. é«˜ç²¾åº¦é…ç½® (å‡å°‘è¯¯æŠ¥)
```bash
python run_bacl_training.py \
  --config_type "high_precision" \
  --output_dir "./lora-bacl-high-precision"
```

#### 3. é«˜å¬å›é…ç½® (å‡å°‘æ¼æŠ¥)
```bash
python run_bacl_training.py \
  --config_type "high_recall" \
  --output_dir "./lora-bacl-high-recall"
```

### ğŸ§ª BACLæµ‹è¯•
```bash
python run_bacl_testing.py \
  --test_data "./data/r789-b-50000_test.xlsx" \
  --training_dir "./lora-bacl-standard" \
  --output_dir "./bacl_test_results"
```

## ğŸ“ˆ æŠ€æœ¯è·¯çº¿æ€»ç»“

### æ ¸å¿ƒæ¼”è¿›é€»è¾‘
1. **Phase 1.0**: å»ºç«‹åŸºç¡€èƒ½åŠ›ï¼ŒéªŒè¯æŠ€æœ¯å¯è¡Œæ€§
2. **Phase 2.0**: è¯†åˆ«å…³é”®é—®é¢˜ï¼Œå¼•å…¥ä¸“é—¨ä¼˜åŒ– (Focal Loss)
3. **Phase 3.0**: èšç„¦æ ¸å¿ƒç›®æ ‡ï¼Œé©å‘½æ€§æ¶æ„åˆ›æ–° (BACL)

### å…³é”®æŠ€æœ¯å†³ç­–
- **ç®€åŒ–ä»»åŠ¡å¤æ‚åº¦**: 6åˆ†ç±» â†’ 2åˆ†ç±»ï¼Œèšç„¦æ ¸å¿ƒä¸šåŠ¡éœ€æ±‚
- **åˆ›æ–°æŸå¤±è®¾è®¡**: æ ‡å‡†æŸå¤± â†’ è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”æŸå¤±
- **æ¶æ„æ·±åº¦ä¼˜åŒ–**: å•ä¸€åˆ†ç±»å™¨ â†’ åŒé€šé“+å¯¹æŠ—è§£è€¦
- **ç«¯åˆ°ç«¯ä¼˜åŒ–**: ä»æ•°æ®å¤„ç†åˆ°æ¨¡å‹æ¨ç†çš„å…¨é“¾è·¯ä¼˜åŒ–

### é¢„æœŸä¸šåŠ¡ä»·å€¼
- **é™æœ¬å¢æ•ˆ**: å‡å°‘äººå·¥å®¡æ ¸å·¥ä½œé‡
- **æå‡ç”¨æˆ·ä½“éªŒ**: é™ä½è¯¯æŠ¥å¯¹æ­£å¸¸ç”¨æˆ·çš„å½±å“
- **ä¿éšœå†…å®¹å®‰å…¨**: æœ€å¤§ç¨‹åº¦å‡å°‘è¿è§„å†…å®¹æ¼æŠ¥
- **å¢å¼ºç³»ç»Ÿç¨³å®šæ€§**: é«˜ç½®ä¿¡åº¦é¢„æµ‹æå‡ç³»ç»Ÿå¯é æ€§

## ğŸ”® æœªæ¥å‘å±•æ–¹å‘

### çŸ­æœŸä¼˜åŒ– (ä¸‹ä¸€é˜¶æ®µ)
- **å¤šæ¨¡æ€èåˆ**: æ–‡æœ¬+å›¾åƒçš„è”åˆå®¡æ ¸
- **å®æ—¶ä¼˜åŒ–**: åœ¨çº¿å­¦ä¹ å’Œæ¨¡å‹è‡ªé€‚åº”
- **è¾¹ç¼˜éƒ¨ç½²**: æ¨¡å‹å‹ç¼©å’Œæ¨ç†åŠ é€Ÿ

### é•¿æœŸæ„¿æ™¯
- **é€šç”¨åŒ–å¹³å°**: æ”¯æŒå¤šç§å†…å®¹å®¡æ ¸åœºæ™¯
- **æ™ºèƒ½åŒ–è¿è¥**: è‡ªåŠ¨åŒ–çš„æ¨¡å‹è¿­ä»£å’Œä¼˜åŒ–
- **è¡Œä¸šæ ‡å‡†**: æˆä¸ºå†…å®¹å®‰å…¨å®¡æ ¸çš„æŠ€æœ¯æ ‡æ†

---

*æœ¬é¡¹ç›®ä»£è¡¨äº†åœ¨å†…å®¹å®‰å…¨å®¡æ ¸é¢†åŸŸçš„æ·±åº¦æŠ€æœ¯æ¢ç´¢ï¼Œä»åŸºç¡€å¾®è°ƒåˆ°è¾¹ç•Œæ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ çš„å®Œæ•´æ¼”è¿›è·¯çº¿ï¼Œä½“ç°äº†AIæŠ€æœ¯åœ¨å®é™…ä¸šåŠ¡åœºæ™¯ä¸­çš„æŒç»­åˆ›æ–°ä¸ä¼˜åŒ–ã€‚*
