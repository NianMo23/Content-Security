# V5.0 原始模型训练和测试框架

## 概述

V5.0版本使用原始的Qwen3模型，不修改分类头，保留原本的词元向量，通过生成式方法进行6分类任务。

## 主要特性

- **原始模型架构**：保持Qwen3模型的原始结构，不添加分类头
- **生成式分类**：通过提示工程和生成式方法进行分类
- **LoRA微调**：使用LoRA技术进行参数高效微调
- **多GPU支持**：支持分布式训练和推理
- **全面评估**：包含6分类、二分类、漏报误报分析

## 文件结构

```
v5.0/
├── qwen3_original_model.py      # 原始模型定义
├── train_original_multi_gpu.py  # 多GPU训练脚本
├── test_original_multi_gpu.py   # 多GPU测试脚本
└── README.md                    # 说明文档
```

## 模型架构

### qwen3_original_model.py

```python
class Qwen3OriginalForClassification:
    """
    使用原始Qwen3模型，不做任何修改，通过生成式方法进行分类
    """
```

**核心特性：**
- 保留原始的lm_head层（151936个词元）
- 通过生成式提示进行分类
- 支持6个分类标签：正常、歧视、违法违规、政治安全、暴恐、色情低俗

**分类方法：**
1. 构建分类提示：`"请对以下文本进行分类，从以下选项中选择一个：正常、歧视、违法违规、政治安全、暴恐、色情低俗。\n文本：{text}\n分类结果："`
2. 获取每个标签token的logits
3. 计算分类概率

## 使用方法

### 1. 训练

```bash
python train_original_multi_gpu.py \
    --checkpoint /path/to/qwen3-1.7b \
    --train_data ../data/balanced_train.xlsx \
    --val_data ../data/balanced_val.xlsx \
    --output_dir ../original-model-output \
    --gpu_ids 0,1,2,3 \
    --batch_size 8 \
    --learning_rate 1e-5 \
    --num_epochs 10
```

**主要参数：**
- `--checkpoint`: 原始Qwen3模型路径
- `--train_data`: 训练数据路径
- `--val_data`: 验证数据路径
- `--output_dir`: 输出目录
- `--gpu_ids`: 使用的GPU ID
- `--batch_size`: 批次大小（建议8，原始模型内存占用较大）
- `--learning_rate`: 学习率（建议1e-5，较小的学习率）

**LoRA参数：**
- `--lora_r`: LoRA秩（默认8）
- `--lora_alpha`: LoRA缩放因子（默认16）
- `--lora_dropout`: LoRA dropout（默认0.1）

### 2. 测试

```bash
python test_original_multi_gpu.py \
    --checkpoint /path/to/qwen3-1.7b \
    --lora_model ../original-model-output/best_model \
    --test_data ../data/r2323-b-50000.xlsx \
    --gpu_ids 0,1,2,3 \
    --batch_size 8
```

**主要参数：**
- `--checkpoint`: 原始Qwen3模型路径
- `--lora_model`: 训练好的LoRA模型路径
- `--test_data`: 测试数据路径
- `--gpu_ids`: 使用的GPU ID

## 数据格式

训练和测试数据需要Excel格式，包含以下字段：

- `text_cn`: 待分类的文本内容
- `extracted_label`: 标签（支持文本或数字格式）

**标签映射：**
```python
label_map = {
    '正常': 0,
    '歧视': 1,
    '违法违规': 2,
    '政治安全': 3,
    '暴恐': 4,
    '色情低俗': 5
}
```

## 输出结果

### 训练输出

- **模型检查点**：保存在指定输出目录
- **训练日志**：`training.log`
- **超参数配置**：`hyperparameters.json`
- **最佳模型**：`best_model/`

### 测试输出

**控制台输出：**
```
=== 多GPU测试集结果 ===
Loss: 0.1234
6分类准确率: 0.9567
F1: 0.9456
Precision: 0.9445
Recall: 0.9467
二分类准确率: 0.9678

=== 【正常类误报分析】 ===
正常内容误报率: 0.0234 (123/5267)

=== 【异常类漏报分析】 ===
总漏报率(异常->正常): 0.0345 (89/2578)
```

**JSON结果文件：**
- 完整的测试配置和结果
- 每类别详细指标
- 漏报误报分析
- 混淆矩阵数据

## 与其他版本的区别

### vs V4.0（修改分类头版本）

| 特性 | V4.0 | V5.0 |
|------|------|------|
| 模型架构 | 修改lm_head为分类头 | 保持原始架构 |
| 分类方法 | 直接分类 | 生成式分类 |
| 参数量 | 较少可训练参数 | 保持原始参数量 |
| 内存占用 | 较低 | 较高 |
| 推理速度 | 较快 | 较慢（需要生成） |
| 模型兼容性 | 需要自定义模型类 | 完全兼容原始模型 |

### 优势

1. **完全兼容**：与原始Qwen3模型完全兼容
2. **保持能力**：保留模型的原始生成能力
3. **灵活性**：可以轻松调整分类提示
4. **可解释性**：生成式分类更容易理解

### 劣势

1. **内存占用**：需要更多GPU内存
2. **推理速度**：生成式分类较慢
3. **训练复杂度**：需要处理生成式训练

## 注意事项

1. **内存要求**：原始模型需要更多GPU内存，建议使用较小的batch_size
2. **学习率**：建议使用较小的学习率（1e-5）
3. **训练时间**：生成式训练可能需要更长时间
4. **提示工程**：分类效果依赖于提示的设计质量

## 性能优化建议

1. **批次大小**：根据GPU内存调整，建议从8开始
2. **梯度累积**：使用梯度累积来模拟更大的批次
3. **混合精度**：启用FP16以节省内存
4. **LoRA参数**：适当调整LoRA的r和alpha参数

## 故障排除

### 常见问题

1. **CUDA内存不足**：
   - 减小batch_size
   - 启用梯度检查点
   - 使用更少的GPU

2. **训练不收敛**：
   - 调整学习率
   - 检查数据质量
   - 调整LoRA参数

3. **生成结果不稳定**：
   - 调整温度参数
   - 优化提示模板
   - 增加训练数据

## 扩展功能

可以通过以下方式扩展功能：

1. **自定义提示**：修改分类提示模板
2. **多轮对话**：支持上下文分类
3. **置信度阈值**：添加置信度判断
4. **增量学习**：支持在线学习更新